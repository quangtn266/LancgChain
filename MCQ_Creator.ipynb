{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaffd7c6-a830-4c36-bce9-47753b720b8c",
   "metadata": {},
   "source": [
    "# MCQ Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae6198-f54e-459b-88f4-cdb3f1fa3f46",
   "metadata": {},
   "source": [
    "## Import libraries and set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1fa466-0a0a-40c7-b1ad-8692f0aa03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead3f865-587e-4ae4-889a-8083e4a4a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a26d6-d579-4090-85c0-c3a0b28c5a70",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0213ab5-c460-4048-b9aa-cedb668d8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(directory):\n",
    "    loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0430c5a5-99c4-414b-8329-3a317f69a1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/Users/quangtn/Desktop/01_work/01_job/02_ml/Langchain/chapter12/prj/Docs/'\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dedef28-74ad-4981-b070-9e5ec570faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs(documents,  chunk_size=1000, chunk_overlap=20):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                        chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cbe5935-eccb-42a3-987e-771d3ac38dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "docs = split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41165a-d3f4-44c0-91e9-77843d652657",
   "metadata": {},
   "source": [
    "## Generate Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "356c24ff-3a49-4304-85f8-6118290d8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|█████████████████████████████████████████████████████████████████████| 690/690 [00:00<00:00, 195kB/s]\n",
      "1_Pooling/config.json: 100%|█████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 25.0kB/s]\n",
      "README.md: 100%|██████████████████████████████████████████████████████████████████████| 3.69k/3.69k [00:00<00:00, 738kB/s]\n",
      "config.json: 100%|████████████████████████████████████████████████████████████████████████| 629/629 [00:00<00:00, 160kB/s]\n",
      "config_sentence_transformers.json: 100%|█████████████████████████████████████████████████| 122/122 [00:00<00:00, 32.2kB/s]\n",
      "pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████| 90.9M/90.9M [00:12<00:00, 7.12MB/s]\n",
      "sentence_bert_config.json: 100%|███████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 21.8kB/s]\n",
      "special_tokens_map.json: 100%|███████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 47.9kB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 624kB/s]\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████| 314/314 [00:00<00:00, 186kB/s]\n",
      "vocab.txt: 100%|████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 447kB/s]\n",
      "modules.json: 100%|██████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 99.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f61d6273-bf25-4d62-927f-59371baec99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello friend\")\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42040d43-b3dc-40fb-ab25-28fa7c16f23b",
   "metadata": {},
   "source": [
    "## Vector store PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70dd0204-fa16-4666-ae8c-edbf3858827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=\"b0f95d6b-af15-4fda-89e8-d39baadae247\",\n",
    "    environment=\"gcp-starter\"\n",
    ")\n",
    "\n",
    "index_name=\"mcq-creator\"\n",
    "\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d305aa-ac11-4688-a573-b80aad8ce7a7",
   "metadata": {},
   "source": [
    "## Retrieve Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7059bcf-e359-4053-a901-13b6f3981291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similiar_docs(query, k=2):\n",
    "    similiar_docs = index.similarity_search(query, k=k)\n",
    "    return similiar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca560e26-78be-4a72-989b-89a0d20b54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "830aee8a-d7cd-4fdb-b9ef-37b6c6b0bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quangtn/opt/anaconda3/envs/bentoML/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(client=InferenceAPI(api_url='https://api-inference.huggingface.co/pipeline/text-generation/bigscience/bloom', task='text-generation', options={'wait_for_model': True, 'use_gpu': False}), repo_id='bigscience/bloom', model_kwargs={'temperature': 1e-10})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceHub(repo_id=\"bigscience/bloom\", model_kwargs={\"temperature\":1e-10})\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba5c64e2-8454-40cb-b344-48b735fe4635",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85ef4403-59fa-48f6-b03a-2b5ff9cec14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7f6debe-ea25-4441-9260-40d0edf05d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    relevant_docs=get_similiar_docs(query)\n",
    "    print(relevant_docs)\n",
    "    response = chain.run(input_documents=relevant_docs, question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ec4d4fe-1394-4784-ad43-37ca340b2d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"India's struggle for independence from British colonial rule is a significant chapter in its history. \\nLed by Mahatma Gandhi and other freedom fighters, the non-violent resistance movement \\ngained momentum and eventually led to India's independence on August 15, 1947. This day is \\ncelebrated annually as Independence Day.\\nIndia's economy is one of the fastest-growing in the world. It has transitioned from an agrarian \\neconomy to a service-oriented and industrialized economy. The country is known for its \\nsoftware and information technology services, pharmaceuticals, textiles, agriculture, and \\nmanufacturing sectors. Major cities like Mumbai, Delhi, Bangalore, and Chennai are hubs of \\nbusiness and commerce, attracting investments and fostering innovation.\\nDelhi is the capital of India\", metadata={'page': 0.0, 'source': '/Users/quangtn/Desktop/01_work/01_job/02_ml/Langchain/chapter12/prj/Docs/Doc 1.pdf'}), Document(page_content='However, India also faces various socio-economic challenges. Poverty, income inequality, and \\nunemployment are persistent issues that the country strives to address. Efforts are being made\\nto improve education, healthcare, infrastructure, and social welfare programs to uplift \\nmarginalized sections of society.\\nEducation plays a vital role in India, with a strong emphasis on academic excellence. The \\ncountry has a vast network of schools, colleges, and universities, producing a large number of \\ngraduates every year. Indian professionals have made significant contributions in various fields \\nglobally, particularly in science, technology, engineering, and mathematics (STEM).\\nThe Indian film industry, popularly known as Bollywood, is a global phenomenon, producing the\\nlargest number of films annually. Indian cinema reflects the diversity and cultural richness of \\nthe country and has a massive following both within India and among the Indian diaspora \\nworldwide.', metadata={'page': 0.0, 'source': '/Users/quangtn/Desktop/01_work/01_job/02_ml/Langchain/chapter12/prj/Docs/Doc 2.pdf'})]\n",
      "\n",
      "India's economy is one of the fastest-growing in the world. It has transitioned from\n"
     ]
    }
   ],
   "source": [
    "out_query = \"How's Inidia's economy?\"\n",
    "answer = get_answer(out_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a769172-2b47-424c-a181-ccba56479acc",
   "metadata": {},
   "source": [
    "## Structure the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66f2f5ea-dd79-45e5-a3c0-1e4f45b83777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate,\\\n",
    "        HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a3552db-54dd-4739-a995-7d87a3906b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='question', description='Question generated from providedinput text data', type='string'), ResponseSchema(name='choices', description='Available options for amultiple-choice question in comma separated.', type='string'), ResponseSchema(name='answer', description='Correct answer for the asked question', type='string')])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"question\", description=\"Question generated from provided\" \\\n",
    "    \"input text data\"),\n",
    "    ResponseSchema(name=\"choices\", description=\"Available options for a\" \\\n",
    "    \"multiple-choice question in comma separated.\"),\n",
    "    ResponseSchema(name=\"answer\", description=\"Correct answer for the asked question\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26627d19-64ad-4ead-b359-f78317216dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"question\": string  // Question generated from providedinput text data\n",
      "\t\"choices\": string  // Available options for amultiple-choice question in comma separated.\n",
      "\t\"answer\": string  // Correct answer for the asked question\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afc8daf5-f208-4b2a-9c3b-bc61b9fc0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9c77377-a22e-4cd7-85db-f494a2eb7892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fceb612d670>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fce80299d90>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "826dae55-33fa-466f-a787-d1e3db2b31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "        When a text input is given by the user, please generate multiple choice\n",
    "        questions from it along with the correct answer.\n",
    "        \\n{format_instructions}\\n{user_prompt}\n",
    "        \"\"\")\n",
    "    ],\n",
    "    input_variables = [\"user_prompt\"],\n",
    "    partial_variables = {\"format_instructions\" :format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c49dd18-29ed-4258-a1b9-5f459fb30511",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_query = prompt.format_prompt(user_prompt = answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13d8ca4b-0b50-4a4b-aae4-c91b7837973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='\\n        When a text input is given by the user, please generate multiple choice\\n        questions from it along with the correct answer.\\n        \\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"question\": string  // Question generated from providedinput text data\\n\\t\"choices\": string  // Available options for amultiple-choice question in comma separated.\\n\\t\"answer\": string  // Correct answer for the asked question\\n}\\n```\\n\\nIndia\\'s economy is one of the fastest-growing in the world. It has transitioned from\\n        ')]\n"
     ]
    }
   ],
   "source": [
    "print(final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "870cfdda-c9e3-4b12-bc73-3d9464ff9245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\n        When a text input is given by the user, please generate multiple choice\\n        questions from it along with the correct answer.\\n        \\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"question\": string  // Question generated from providedinput text data\\n\\t\"choices\": string  // Available options for amultiple-choice question in comma separated.\\n\\t\"answer\": string  // Correct answer for the asked question\\n}\\n```\\n\\nIndia\\'s economy is one of the fastest-growing in the world. It has transitioned from\\n        ')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7115d57-0894-44f7-9739-0f43470f4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_query_output = chat_model(final_query.to_messages())\n",
    "print(final_query_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a80e654-116e-4ecc-baa7-42e458cc9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = final_query_output.content\n",
    "json_string = re.search(r'{(.*?)}', markdown_text, re.DOTALL).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92402e63-e422-4166-9946-493eeffeff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
